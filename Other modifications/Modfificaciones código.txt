Modificaciones Kernel: 
def conv_block(input, filters):
    x = Conv2D(filters, 5, padding="same")(input)  # Changed kernel size to 5
    x = BatchNormalization()(x)
    x = Activation("relu")(x)

    x = Conv2D(filters, 5, padding="same")(x)  # Changed kernel size to 5
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x

def decoder_block(input, skip, filters):
    x = Conv2DTranspose(filters, 5, strides=2, padding="same")(input)  # Changed kernel size to 5
    x = concatenate([x, skip])
    x = conv_block(x, filters)
    return x

Modificaciones Padding:

def conv_block(input, filters):
    x = Conv2D(filters, 3, padding="valid")(input)  # Changed padding to valid
    x = BatchNormalization()(x)
    x = Activation("relu")(x)

    x = Conv2D(filters, 3, padding="valid")(x)  # Changed padding to valid
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x

def decoder_block(input, skip, filters):
    x = Conv2DTranspose(filters, 2, strides=2, padding="valid")(input)  # Changed padding to valid
    x = concatenate([x, skip])
    x = conv_block(x, filters)
    return x

Modificaciones Optimizer & Hiperparameters:

	ADAM: 
from tensorflow.keras.optimizers import Adam

optimizer = Adam(learning_rate=0.0001)  # Changed learning rate to 0.0001
model.compile(optimizer=optimizer, loss="binary_crossentropy", metrics=["accuracy"])
	SDG: 
from tensorflow.keras.optimizers import RMSprop

optimizer = RMSprop(learning_rate=0.001)  # RMSprop optimizer
model.compile(optimizer=optimizer, loss="binary_crossentropy", metrics=["accuracy"])
	RMSprop:
from tensorflow.keras.optimizers import RMSprop

optimizer = RMSprop(learning_rate=0.001)  # RMSprop optimizer
model.compile(optimizer=optimizer, loss="binary_crossentropy", metrics=["accuracy"])

Modificaciones Loss Function:

def dice_loss(y_true, y_pred):
    numerator = 2 * tf.reduce_sum(y_true * y_pred)
    denominator = tf.reduce_sum(y_true + y_pred)
    return 1 - numerator / (denominator + tf.keras.backend.epsilon())

model.compile(optimizer="adam", loss=dice_loss, metrics=["accuracy"])

Modificaciones Outputlayer:

output = Conv2D(1, (1, 1), padding="same", activation="sigmoid")(d4)  # Sigmoid activation

output = Conv2D(num_classes, (1, 1), padding="same", activation="softmax")(d4)  # Softmax activation

